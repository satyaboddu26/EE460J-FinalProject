{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HaHackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score, roc_curve, auc, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  is_humor  \\\n",
       "0   1  TENNESSEE: We're the best state. Nobody even c...         1   \n",
       "1   2  A man inserted an advertisement in the classif...         1   \n",
       "2   3  How many men does it take to open a can of bee...         1   \n",
       "3   4  Told my mom I hit 1200 Twitter followers. She ...         1   \n",
       "4   5  Roses are dead. Love is fake. Weddings are bas...         1   \n",
       "\n",
       "   humor_rating  humor_controversy  offense_rating  \n",
       "0          2.42                1.0             0.2  \n",
       "1          2.50                1.0             1.1  \n",
       "2          1.95                0.0             2.4  \n",
       "3          2.11                1.0             0.0  \n",
       "4          2.78                0.0             0.1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['is_humor']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n",
      "Numer of samples with no words found: 2 / 6000\n",
      "Numer of samples with no words found: 0 / 2000\n"
     ]
    }
   ],
   "source": [
    "# Course URL:\n",
    "# https://deeplearningcourses.com/c/natural-language-processing-with-deep-learning-in-python\n",
    "# https://udemy.com/natural-language-processing-with-deep-learning-in-python\n",
    "\n",
    "glove_vectors = \"glove.6B.300d.txt\"\n",
    "\n",
    "class GloveVectorizer:\n",
    "  def __init__(self):\n",
    "    # load in pre-trained word vectors\n",
    "    print('Loading word vectors...')\n",
    "    word2vec = {}\n",
    "    embedding = []\n",
    "    idx2word = []\n",
    "    with open(glove_vectors, encoding=\"utf8\") as f:\n",
    "      # is just a space-separated text file in the format:\n",
    "      # word vec[0] vec[1] vec[2] ...\n",
    "      for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)\n",
    "    print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "    # save for later\n",
    "    self.word2vec = word2vec\n",
    "    self.embedding = np.array(embedding)\n",
    "    self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "    self.V, self.D = self.embedding.shape\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.lower().split()\n",
    "      vecs = []\n",
    "      for word in tokens:\n",
    "        if word in self.word2vec:\n",
    "          vec = self.word2vec[word]\n",
    "          vecs.append(vec)\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Word2VecVectorizer:\n",
    "  def __init__(self):\n",
    "    print(\"Loading in word vectors...\")\n",
    "    self.word_vectors = KeyedVectors.load_word2vec_format(\n",
    "      '../large_files/GoogleNews-vectors-negative300.bin',\n",
    "      binary=True\n",
    "    )\n",
    "    print(\"Finished loading in word vectors\")\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    # determine the dimensionality of vectors\n",
    "    v = self.word_vectors.get_vector('king')\n",
    "    self.D = v.shape[0]\n",
    "\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.split()\n",
    "      vecs = []\n",
    "      m = 0\n",
    "      for word in tokens:\n",
    "        try:\n",
    "          # throws KeyError if word not found\n",
    "          vec = self.word_vectors.get_vector(word)\n",
    "          vecs.append(vec)\n",
    "          m += 1\n",
    "        except KeyError:\n",
    "          pass\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = GloveVectorizer()\n",
    "# vectorizer = Word2VecVectorizer()\n",
    "Xtrain = vectorizer.fit_transform(X_train)\n",
    "Ytrain = y_train\n",
    "\n",
    "Xtest = vectorizer.transform(X_test)\n",
    "Ytest = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "test score: 0.8155\n"
     ]
    }
   ],
   "source": [
    "# create the model, train it, print scores\n",
    "#model = RandomForestClassifier(n_estimators=200)\n",
    "etc_model = ExtraTreesClassifier(n_estimators=200)\n",
    "etc_model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", etc_model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", etc_model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "test score: 0.804\n"
     ]
    }
   ],
   "source": [
    "# create the model, train it, print scores\n",
    "rfc_model = RandomForestClassifier(n_estimators=200)\n",
    "rfc_model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", rfc_model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", rfc_model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.0\n",
      "test score: 0.817\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "# create the model, train it, print scores\n",
    "#model = RandomForestClassifier(n_estimators=200)\n",
    "xgb_model = XGBClassifier(objective=\"binary:logistic\", eval_metric=\"auc\")\n",
    "xgb_model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", xgb_model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", xgb_model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9868333333333333\n",
      "test score: 0.8335\n"
     ]
    }
   ],
   "source": [
    "# CatBooost\n",
    "#cat_features = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23]\n",
    "params = {'loss_function':'Logloss',\n",
    "          'eval_metric':'AUC:hints=skip_train~false',\n",
    "        #  'cat_features': cat_features,\n",
    "        #'task_type': \"GPU\",\n",
    "          'verbose': 0,\n",
    "        #  'border_count': 254,\n",
    "          'random_seed': 42\n",
    "         }\n",
    "cb_model = CatBoostClassifier(**params)\n",
    "cb_model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", cb_model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", cb_model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8947373986344666\n",
      "Accuracy: 0.817\n",
      "F1 score: 0.8568075117370891\n"
     ]
    }
   ],
   "source": [
    "model = xgb_model\n",
    "\n",
    "print(f\"AUC: {roc_auc_score(Ytest, model.predict_proba(Xtest)[:, 1])}\")\n",
    "print(f\"Accuracy: {model.score(Xtest, Ytest)}\")\n",
    "print(f\"F1 score: {f1_score(Ytest, model.predict(Xtest))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of samples with no words found: 0 / 1000\n"
     ]
    }
   ],
   "source": [
    "public_data = pd.read_csv(\"public_test.csv\")\n",
    "#public_data.head()\n",
    "public_X = public_data['text']\n",
    "public_X.head()\n",
    "public_Xtest = vectorizer.transform(public_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  is_humor\n",
      "0  9001         1\n",
      "1  9002         0\n",
      "2  9003         1\n",
      "3  9004         1\n",
      "4  9005         1\n"
     ]
    }
   ],
   "source": [
    "is_humor_pred = cb_model.predict_proba(public_Xtest)[:,1]\n",
    "test_predictions =[round(value) for value in is_humor_pred]\n",
    "submission = pd.DataFrame({\"id\":public_data[\"id\"],\"is_humor\":test_predictions})\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"jin_is_humor_GloVe_CatBoost.csv\"\n",
    "submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
